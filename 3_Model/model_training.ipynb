{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, Imports, and Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to run the correct PyTorch install command such as\n",
    "\n",
    "```conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia```\n",
    "\n",
    "in your conda environment before running this notebook.\n",
    "\n",
    "This command can be found from the official PyTorch website: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "import sys\n",
    "sys.path.insert(1, \"../libs\")\n",
    "from postgres_data import load_postgresql_data\n",
    "\n",
    "# General imports\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# ML imports\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "SEED = 777\n",
    "VALIDATION_RATIO = 0.2 # 20% of training data will be used for validation\n",
    "\n",
    "MODEL_TYPE = \"bert-base-multilingual-uncased\"\n",
    "L_RATE = 1e-5\n",
    "MAX_LEN = 80\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16 # For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "NUM_CORES = 0 # os.cpu_count()\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "CSV_DATA_DIR = '../1_CSV_Data'\n",
    "MODELS_DIR = \"./models\"\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "# Check for GPU to speed up training\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    # device = torch.device(\"cpu\")\n",
    "    raise Exception(\"No GPU available, please setup GPU with CUDA before running this notebook\")\n",
    "\n",
    "# Note: For TPU\n",
    "# device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test dataframes\n",
    "train_df_presplit, test_df = load_postgresql_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  58176\n",
      "Validation data size:  14544\n"
     ]
    }
   ],
   "source": [
    "#train_test_split to create validation set\n",
    "train_df, val_df = train_test_split(train_df_presplit, random_state=SEED, test_size=VALIDATION_RATIO)\n",
    "train_df.reset_index(drop=True, inplace=True) # reset indecies, otherwise indecies would be retained from original df\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "print(\"Train data size: \", train_df.size)\n",
    "print(\"Validation data size: \", val_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Datasets to use BERT's encoding, and DataLoaders for each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105879"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE, do_lower_case=True)\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encode a sentence with BERT, we are required to:\n",
    "\n",
    "  -  Add special tokens to the start and end of each sentence.\n",
    "  -  Pad & truncate all sentences to a single constant length.\n",
    "  -  Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence_pair(sentence1, sentence2):\n",
    "    \"\"\"\n",
    "    Encode a sentence pair using BERT tokenizer and return the encoded array\n",
    "    \"\"\"\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sentence1, sentence2,           # Sentences to encode.\n",
    "        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad or truncate.\n",
    "        padding = \"max_length\",\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        return_tensors = \"pt\",          # Return pytorch tensors.\n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    # These are torch tensors\n",
    "    padded_token_list = encoded_dict[\"input_ids\"][0]\n",
    "    att_mask = encoded_dict[\"attention_mask\"][0]\n",
    "    token_type_ids = encoded_dict[\"token_type_ids\"][0]\n",
    "\n",
    "    return (padded_token_list, att_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):        \n",
    "        self.df_data = df\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get the sentence from the dataframe\n",
    "        sentence1 = self.df_data.loc[index, \"premise\"]\n",
    "        sentence2 = self.df_data.loc[index, \"hypothesis\"]\n",
    "\n",
    "        # Encode the sentences\n",
    "        padded_token_list, att_mask, token_type_ids = encode_sentence_pair(sentence1, sentence2)\n",
    "        \n",
    "        # Convert the target to a torch tensor\n",
    "        target = torch.tensor(self.df_data.loc[index, \"label\"])\n",
    "\n",
    "        sample = (padded_token_list, att_mask, token_type_ids, target)        \n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df_data = df\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get the sentence from the dataframe\n",
    "        sentence1 = self.df_data.loc[index, \"premise\"]\n",
    "        sentence2 = self.df_data.loc[index, \"hypothesis\"]\n",
    "\n",
    "        # Encode the sentences\n",
    "        padded_token_list, att_mask, token_type_ids = encode_sentence_pair(sentence1, sentence2)               \n",
    "\n",
    "        sample = (padded_token_list, att_mask, token_type_ids)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\n",
      "152\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "train_data = LabelledDataset(train_df)\n",
    "val_data = LabelledDataset(val_df)\n",
    "test_data = TestDataset(test_df)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_CORES,\n",
    "    pin_memory=True # Speeds up data transfer from CPU to GPU\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_CORES,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_CORES,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 80])\n",
      "torch.Size([16, 80])\n",
      "torch.Size([16, 80])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# testing out our dataloader to ensure correct output of 1 batch\n",
    "train_iter = iter(train_dataloader)\n",
    "padded_token_list, att_mask, token_type_ids, target = next(train_iter)\n",
    "\n",
    "print(padded_token_list.shape)\n",
    "print(att_mask.shape)\n",
    "print(token_type_ids.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_TYPE,\n",
    "    num_labels = 3, # The number of output labels--In our case 3\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (3, 768)\n",
      "classifier.bias                                                 (3,)\n"
     ]
    }
   ],
   "source": [
    "# Print information about the model\n",
    "\n",
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print(\"The BERT model has {:} different named parameters.\\n\".format(len(params)))\n",
    "\n",
    "print(\"==== Embedding Layer ====\\n\")\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print(\"\\n==== First Transformer ====\\n\")\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print(\"\\n==== Output Layer ====\\n\")\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test of the model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_iter)\n",
    "\n",
    "b_input_ids = batch[0].to(device)\n",
    "b_input_mask = batch[1].to(device)\n",
    "b_token_type_ids = batch[2].to(device)\n",
    "b_labels = batch[3].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "    b_input_ids, \n",
    "    token_type_ids=b_token_type_ids, \n",
    "    attention_mask=b_input_mask,\n",
    "    labels=b_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(1.1641, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.8905,  0.5045, -0.1344],\n",
       "        [ 1.3952,  0.4899, -0.3179],\n",
       "        [ 0.3276,  0.2253, -0.0970],\n",
       "        [ 1.2055,  0.4207, -0.1915],\n",
       "        [ 0.0345,  0.0413, -0.0766],\n",
       "        [ 0.5743,  0.2739, -0.1787],\n",
       "        [ 0.6232,  0.2485, -0.1518],\n",
       "        [ 0.3149,  0.1726, -0.0786],\n",
       "        [ 0.7125,  0.3588, -0.1735],\n",
       "        [ 0.9392,  0.7605, -0.0641],\n",
       "        [ 0.8242,  0.4218, -0.2156],\n",
       "        [ 0.7595,  0.5397,  0.0058],\n",
       "        [ 1.2743,  0.4398, -0.1960],\n",
       "        [ 1.0467,  0.5713, -0.0704],\n",
       "        [ 0.7264,  0.5651, -0.1569],\n",
       "        [ 1.2683,  0.7980, -0.2768]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predictions for each training example in the batch.\n",
    "preds = outputs[1].detach().cpu().numpy()\n",
    "\n",
    "y_true = b_labels.detach().cpu().numpy()\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the accuracy without any fine tuning based on the first batch of the training set.\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=L_RATE, eps = 1e-8) # eps is added to avoid nan (term that is added to the denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * NUM_EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "    num_training_steps = total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Store the average loss and validation accuracy after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "val_loss_values = []\n",
    "val_accuracy_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    '''\n",
    "    Function to calculate the accuracy of our predictions vs labels\n",
    "    '''\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop:\n",
    "\n",
    " *   Unpack our data inputs and labels\n",
    " *   Load data onto the GPU for acceleration\n",
    " *   Clear out the gradients calculated in the previous pass.\n",
    "     *   In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    " *   Forward pass (feed input data through the network)\n",
    " *   Backward pass (backpropagation)\n",
    " *   Tell the network to update parameters with optimizer.step()\n",
    " *   Track variables for monitoring progress\n",
    "\n",
    " Evalution loop:\n",
    "\n",
    " *   Unpack our data inputs and labels\n",
    " *   Load data onto the GPU for acceleration\n",
    " *   Forward pass (feed input data through the network)\n",
    " *   Compute loss on our validation data and track variables for monitoring progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warning\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "# import logging\n",
    "# logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "          \n",
    "    print(\"\")\n",
    "    print(\"======== Epoch {:} / {:} ========\".format(epoch + 1, NUM_EPOCHS))\n",
    "    print(\"Training...\")\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "            \n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print(\"  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.    Loss: {:0.2f}.    Accuracy: {:0.2f}\".format(\n",
    "                step, \n",
    "                len(train_dataloader), \n",
    "                elapsed, \n",
    "                sum(loss_values[-40:])/40, \n",
    "                sum(accuracy_values[-40:])/40)\n",
    "            )\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_token_type_ids = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass.\n",
    "        outputs = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=b_token_type_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        # Move to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        batch_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the training loss and accuracy over all of the batches so we can get the average at the end\n",
    "        total_loss += loss.item() \n",
    "        total_accuracy += batch_accuracy\n",
    "\n",
    "        # Store the loss and accuracy value for plotting the learning curve.\n",
    "        loss_values.append(loss.item())\n",
    "        accuracy_values.append(batch_accuracy)\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\".\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Take a step and update parameters based on the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Scheduler updates the learning rate over time.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Finished training this epoch.\n",
    "    # Calculate average loss over all of the batches.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    avg_train_accuracy = total_accuracy / len(train_dataloader)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Average training accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
    "    print(\"  Final training loss: {0:.2f}\".format(loss_values[-1]))\n",
    "    print(\"  Final training accuracy: {0:.2f}\".format(accuracy_values[-1]))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_loss, total_eval_accuracy = 0, 0\n",
    "    num_eval_steps = 0\n",
    "\n",
    "    # For each batch of validation data...\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        # Unpack batch from our dataloader.\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_token_type_ids = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during evaluation\n",
    "        with torch.no_grad():\n",
    "            outputs = model( # Logits are the model outputs prior to applying an activation function such as softmax.\n",
    "                b_input_ids,\n",
    "                token_type_ids=b_token_type_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels\n",
    "            )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        # Move to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        batch_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumlate loss and accuracy.\n",
    "        total_eval_loss += loss.item()\n",
    "        total_eval_accuracy += batch_eval_accuracy\n",
    "\n",
    "        num_eval_steps += 1\n",
    "\n",
    "    # Calculate the average loss and accuracy over all batches, and store for plotting.\n",
    "    eval_loss = total_eval_loss / num_eval_steps\n",
    "    eval_accuracy = total_eval_accuracy / num_eval_steps\n",
    "\n",
    "    # Store the loss and accuracy value for plotting the learning curve. We only need to do this once per epoch in validation.\n",
    "    val_loss_values.append(eval_loss)\n",
    "    val_accuracy_values.append(eval_accuracy)\n",
    "\n",
    "    # Print accuracy over all batches\n",
    "    print(\"  Loss: {0:.2f}\".format(eval_loss))\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # Save the model checkpoint    \n",
    "    torch.save(model.state_dict(), '{}/model_checkpoint_{:}_{}ep_{:0.0f}acc.pt'.format(MODELS_DIR, time.strftime(\"%Y%m%d-%H%M\"), epoch+1, eval_accuracy*100))\n",
    "\n",
    "    # Use the garbage collector to save memory.\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup memory from run\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Evaluting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Smooth the graph a little by averaging the values in groups of k size\n",
    "k = 25\n",
    "smooth_loss_values = [sum(loss_values[(i*k):(i*k)+k]) / float(k) for i in range(0, int(len(loss_values) / k))]\n",
    "print(smooth_loss_values)\n",
    "smooth_loss_values_x = [(i * k) + int(k / 2) for i in range(0, (int(len(loss_values) / k)))]\n",
    "print(smooth_loss_values_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Setup Validation Loss\n",
    "val_loss_values_x = [i * int(len(loss_values) / NUM_EPOCHS) for i in range(1, NUM_EPOCHS + 1)]\n",
    "print(val_loss_values_x)\n",
    "print(val_loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Plot the learning curve.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# plt.plot(loss_values, 'b-o')\u001b[39;00m\n\u001b[0;32m     15\u001b[0m plt\u001b[39m.\u001b[39mplot(smooth_loss_values_x, smooth_loss_values, \u001b[39m'\u001b[39m\u001b[39mr-o\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m plt\u001b[39m.\u001b[39;49mplot(val_loss_values_x, val_loss_values, \u001b[39m'\u001b[39;49m\u001b[39mg-o\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Label the plot.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mTraining loss (Red) vs Validation loss (Green)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dillo\\anaconda3\\envs\\watson\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dillo\\anaconda3\\envs\\watson\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Dillo\\anaconda3\\envs\\watson\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\Dillo\\anaconda3\\envs\\watson\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "# plt.plot(loss_values, 'b-o')\n",
    "plt.plot(smooth_loss_values_x, smooth_loss_values, 'r-o')\n",
    "plt.plot(val_loss_values_x, val_loss_values, 'g-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss (Red) vs Validation loss (Green)\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1e4a03f8790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reload model from disk\n",
    "# Load model from checkpoint\n",
    "path_model = f'{MODELS_DIR}/model_checkpoint_20230827-2223_2ep_62acc.pt'#'models/model_checkpoint_20230827-2225_3ep_63acc.pt'\n",
    "model.load_state_dict(torch.load(path_model))\n",
    "\n",
    "# Send the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Turn off the gradient calculations\n",
    "# This tells the model not to compute or store gradients\n",
    "# This step saves memory and speeds up validation\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 325\r"
     ]
    }
   ],
   "source": [
    "# Final stacked labels list\n",
    "stacked_val_labels = []\n",
    "\n",
    "# Reset the total loss for this epoch.\n",
    "total_val_loss = 0\n",
    "\n",
    "for j, h_batch in enumerate(test_dataloader):\n",
    "\n",
    "    inference_status = 'Batch ' + str(j + 1)\n",
    "\n",
    "    print(inference_status, end='\\r')\n",
    "\n",
    "    b_input_ids = h_batch[0].to(device)\n",
    "    b_input_mask = h_batch[1].to(device)\n",
    "    b_token_type_ids = h_batch[2].to(device)     \n",
    "\n",
    "\n",
    "    outputs = model(b_input_ids, \n",
    "            token_type_ids=b_token_type_ids, \n",
    "            attention_mask=b_input_mask)\n",
    "\n",
    "\n",
    "    # Get the preds\n",
    "    preds = outputs[0]\n",
    "\n",
    "\n",
    "    # Move preds to the CPU\n",
    "    val_preds = preds.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # Stack the predictions.\n",
    "\n",
    "    if j == 0:  # first batch\n",
    "        stacked_val_preds = val_preds\n",
    "\n",
    "    else:\n",
    "        stacked_val_preds = np.vstack((stacked_val_preds, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17804407,  0.36460358,  0.04536536],\n",
       "       [ 1.8994677 , -0.10736712, -0.46736047],\n",
       "       [ 2.2650545 , -0.09548439, -0.58953667],\n",
       "       ...,\n",
       "       [ 0.31025118,  0.02071255,  0.18279883],\n",
       "       [-1.0606146 ,  0.16822244,  0.35274532],\n",
       "       [-1.528332  ,  0.76194555, -0.10589468]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = np.argmax(stacked_val_preds, axis=1)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5195, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  prediction\n",
       "0  c6d58c3f69           1\n",
       "1  cefcc82292           1\n",
       "2  e98005252c           1\n",
       "3  58518c10ba           1\n",
       "4  c32b0d16df           1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sample submission.\n",
    "# The row order in the test set and the sample submission is the same.\n",
    "\n",
    "path = f'{CSV_DATA_DIR}/sample_submission.csv'\n",
    "\n",
    "df_sample = pd.read_csv(path)\n",
    "\n",
    "print(df_sample.shape)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  prediction\n",
       "0  c6d58c3f69           1\n",
       "1  cefcc82292           0\n",
       "2  e98005252c           0\n",
       "3  58518c10ba           2\n",
       "4  c32b0d16df           2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the preds to the prediction column\n",
    "\n",
    "df_sample['prediction'] = test_preds\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: So let me draw a slightly different moral from the saga of beach volleyball as it has evolved in our  If, as Speaker Gingrich says, the price of volleyball is eternal freedom, still it may take a village to raise a volleyball net.\n",
      "Hypothesis: If a village is to be free, Speaker Gingrich believes they should not have a volleyball net. \n",
      "Prediction: contradiction\n",
      "\n",
      "Premise: His proud reserve--a product of 40 years in the spotlight--is refreshing but does not bode well for his capacity to shepherd big ideas through Congress.\n",
      "Hypothesis: He is way too loud.\n",
      "Prediction: neutral\n",
      "\n",
      "Premise: Nash showed up for an MIT New Year's Eve party clad only in a diaper.\n",
      "Hypothesis: Nash had too many nasty pictures on Instagram.\n",
      "Prediction: entailment\n",
      "\n",
      "Premise: you know our church each year has a one of their major fund raisers is you know a garage sale and there's a ton of clothes always you know left over and i take those down to the uh\n",
      "Hypothesis: Our church also has bake sales each year. \n",
      "Prediction: entailment\n",
      "\n",
      "Premise: Wear a nicely ventilated hat and keep to the shade in the street.\n",
      "Hypothesis: The buildings are so low that there is no shade in the streets.\n",
      "Prediction: contradiction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number to label list\n",
    "label_list = ['entailment', 'neutral', 'contradiction']\n",
    "\n",
    "# Sanity check of some english entries compared to their predictions\n",
    "only_en_df = test_df[test_df.lang_abv == 'en']\n",
    "only_en_df = only_en_df.set_index('id')\n",
    "# print(only_en_df)\n",
    "only_en_df['prediction'] = only_en_df.rename(index=df_sample.set_index('id')['prediction']).index\n",
    "only_en_df['prediction'] = only_en_df['prediction'].map(lambda x: label_list[x])\n",
    "\n",
    "for i in range(10,15):\n",
    "    print(\"Premise: {}\\nHypothesis: {}\\nPrediction: {}\\n\".format(only_en_df.iloc[i]['premise'], only_en_df.iloc[i]['hypothesis'],only_en_df.iloc[i]['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission csv file\n",
    "df_sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
